import OpenAI from 'openai';
import { ConversationContext, OpenAIResponse } from '../types';
import logger from '../utils/logger';
import { truncateText } from '../utils/helpers';

export class OpenAIService {
  private client: OpenAI;
  private model: string;
  private maxTokens: number;
  private temperature: number;
  private assistantId: string | null = null;
  private threadStore = new Map<string, string>(); // Store thread IDs per user

  constructor(apiKey: string, model: string = 'gpt-4o-mini', maxTokens: number = 1000, temperature: number = 0.85) {
    this.client = new OpenAI({ apiKey });
    this.model = model;
    this.maxTokens = maxTokens;
    this.temperature = temperature;

    logger.info(`OpenAI service initialized with model: ${model}`);
    this.initializeSaraAssistant();
  }

  async generateResponse(userMessage: string, context: ConversationContext): Promise<OpenAIResponse> {
    try {
      // If Sara assistant is available, use it; otherwise fallback to chat completion
      if (this.assistantId && context.userId) {
        return await this.generateAssistantResponse(userMessage, context.userId);
      } else {
        return await this.generateChatResponse(userMessage, context);
      }
    } catch (error) {
      logger.error('OpenAI API error:', error);

      // Fallback to chat completion if assistant fails
      if (this.assistantId) {
        logger.warn('Assistant failed, falling back to chat completion');
        return await this.generateChatResponse(userMessage, context);
      }

      if (error instanceof Error) {
        if (error.message.includes('rate_limit_exceeded')) {
          throw new Error('Rate limit excedido. Tente novamente em alguns minutos.');
        } else if (error.message.includes('insufficient_quota')) {
          throw new Error('Cota da API OpenAI excedida. Entre em contato com o administrador.');
        } else if (error.message.includes('invalid_api_key')) {
          throw new Error('Chave da API OpenAI inv√°lida.');
        }
      }

      throw new Error('Erro interno do servi√ßo de IA. Tente novamente mais tarde.');
    }
  }

  private async generateAssistantResponse(userMessage: string, userId: string): Promise<OpenAIResponse> {
    try {
      // Get or create thread for this user
      let threadId = this.threadStore.get(userId);
      if (!threadId) {
        const thread = await this.client.beta.threads.create();
        threadId = thread.id;
        this.threadStore.set(userId, threadId);
        logger.debug(`Created new thread ${threadId} for user ${userId}`);
      }

      // Add user message to thread
      await this.client.beta.threads.messages.create(threadId, {
        role: 'user',
        content: userMessage
      });

      // Run the assistant
      const run = await this.client.beta.threads.runs.create(threadId, {
        assistant_id: this.assistantId!,
      });

      // Wait for completion
      let runStatus = await this.client.beta.threads.runs.retrieve(run.id, { thread_id: threadId });
      let attempts = 0;
      const maxAttempts = 30; // 30 seconds timeout

      while (runStatus.status === 'in_progress' || runStatus.status === 'queued') {
        await new Promise(resolve => setTimeout(resolve, 1000));
        runStatus = await this.client.beta.threads.runs.retrieve(run.id, { thread_id: threadId });
        attempts++;

        if (attempts >= maxAttempts) {
          throw new Error('Assistant response timeout');
        }
      }

      if (runStatus.status === 'completed') {
        // Get the assistant's response
        const messages = await this.client.beta.threads.messages.list(threadId);
        const assistantMessages = messages.data.filter(msg =>
          msg.role === 'assistant' && msg.run_id === run.id
        );

        if (assistantMessages.length > 0) {
          const content = assistantMessages[0].content[0];
          const responseText = content.type === 'text' ? content.text.value : 'Resposta n√£o textual recebida.';

          logger.debug('Sara assistant response received', {
            responseLength: responseText.length,
            threadId,
            runId: run.id
          });

          return {
            content: responseText,
            usage: {
              prompt_tokens: runStatus.usage?.prompt_tokens || 0,
              completion_tokens: runStatus.usage?.completion_tokens || 0,
              total_tokens: runStatus.usage?.total_tokens || 0,
            },
            model: 'sara-assistant',
          };
        }
      } else if (runStatus.status === 'requires_action') {
        // Handle function calls if needed
        logger.warn('Assistant requires action - function calls not implemented yet');
        throw new Error('Function calls not implemented');
      } else {
        logger.error('Assistant run failed', { status: runStatus.status, lastError: runStatus.last_error });
        throw new Error(`Assistant run failed: ${runStatus.status}`);
      }

      throw new Error('No assistant response received');
    } catch (error) {
      logger.error('Sara assistant error:', error);
      throw error;
    }
  }

  private async generateChatResponse(userMessage: string, context: ConversationContext): Promise<OpenAIResponse> {
    const messages = this.buildMessagesArray(userMessage, context);

    logger.debug('Sending request to OpenAI Chat', {
      model: this.model,
      messageCount: messages.length,
      userMessage: userMessage.substring(0, 100) + '...'
    });

    const completion = await this.client.chat.completions.create({
      model: this.model,
      messages,
      max_tokens: this.maxTokens,
      temperature: this.temperature,
      stream: false,
    });

    const response = completion.choices[0]?.message?.content || 'Desculpe, n√£o consegui gerar uma resposta.';
    const usage = completion.usage;

    logger.debug('OpenAI chat response received', {
      responseLength: response.length,
      tokensUsed: usage?.total_tokens || 0
    });

    return {
      content: response,
      usage: {
        prompt_tokens: usage?.prompt_tokens || 0,
        completion_tokens: usage?.completion_tokens || 0,
        total_tokens: usage?.total_tokens || 0,
      },
      model: this.model,
    };
  }

  private async initializeSaraAssistant(): Promise<void> {
    try {
      // Try to find existing Sara assistant
      const assistants = await this.client.beta.assistants.list({ limit: 100 });
      let saraAssistant = assistants.data.find(a =>
        a.name === 'Sara - Assistente de Produtividade'
      );

      if (!saraAssistant) {
        // Create Sara assistant if it doesn't exist
        logger.info('Creating Sara assistant...');
        saraAssistant = await this.createSaraAssistant();
      }

      this.assistantId = saraAssistant.id;
      logger.info(`Sara assistant initialized: ${this.assistantId}`);
    } catch (error) {
      logger.warn('Failed to initialize Sara assistant, will use chat completion fallback:', error);
    }
  }

  private async createSaraAssistant(): Promise<OpenAI.Beta.Assistants.Assistant> {
    const assistantConfig = {
      name: "Sara - Assistente de Produtividade",
      description: "Assistente brasileira especializada em produtividade pessoal atrav√©s de micro-metas di√°rias, check-ins personalizados e acompanhamento emp√°tico anti-irrita√ß√£o.",
      instructions: `Voc√™ √© Sara - assistente de produtividade focada em MICRO-METAS DI√ÅRIAS via WhatsApp.

üéØ SUA MISS√ÉO PRINCIPAL:
Ajudar pessoas a baterem 1-3 PEQUENAS metas por dia (n√£o 10 metas, n√£o projetos gigantes - MICRO-A√á√ïES que cabem na vida real).

Por que micro-metas?
‚Ä¢ 3 coisinhas pequenas > 1 objetivo enorme que trava
‚Ä¢ Pessoa sente progresso TODO dia (n√£o s√≥ no fim do m√™s)
‚Ä¢ Sem press√£o, sem culpa, sem burnout

üö´ REGRAS ANTI-IRRITA√á√ÉO (CR√çTICAS):
1. Se usu√°rio diz "hoje n√£o d√°" / "t√° foda" / "0/3" ‚Üí ACEITA sem serm√£o
   - Responda: "Tranquilo! Amanh√£ recome√ßa" ou "0/3 t√° de boa, a vida acontece"

2. Se responde 0/3 por 2+ dias seguidos ‚Üí ofere√ßa ajustar:
   - "Vi que t√° pesado. Quer pausar uns dias? Ou reduzir pra 1 meta s√≥?"

3. Se usu√°rio parece sobrecarregado ‚Üí SUGERE simplificar:
   - "T√° corrido? Escolhe s√≥ 1 coisinha hoje, sem press√£o"

4. NUNCA envie serm√£o motivacional corporativo chato
5. NUNCA fa√ßa guilt-trip ("voc√™ prometeu...", "j√° faz X dias...")
6. NUNCA envie m√∫ltiplas perguntas numa mensagem (uma coisa de cada vez!)

‚úÖ COMO VOC√ä FALA:
‚Ä¢ Portugu√™s brasileiro real: "t√°", "pra", "c√™", "n√©", "rola"
‚Ä¢ Direta mas amiga: "E a√≠, conseguiu fazer?" n√£o "Gostaria de saber se obteve sucesso..."
‚Ä¢ Celebra genuinamente: "Carai, 2/3! Mandou bem!" ou "3/3 limpo! Que dia! üî•"
‚Ä¢ Aceita falha de boa: "0/3? Acontece. Bora recome√ßar amanh√£"
‚Ä¢ Emoji quando faz sentido (n√£o enfia em tudo)
‚Ä¢ VARIA como fala - nunca soa rob√≥tico/decorado

üìè REGRA DOS 30 SEGUNDOS:
‚Ä¢ Suas mensagens devem ser lidas em 30 segundos ou menos
‚Ä¢ 2-3 frases √© o ideal
‚Ä¢ Se precisa explicar algo longo, quebra em partes pequenas

üí° MICRO-PROGRESSO COACHING:
Quando usu√°rio trava ou procrastina, sugira micro-a√ß√£o de 5-10 minutos:
‚Ä¢ "Escolhe uma micro-a√ß√£o de 5 min: abrir 1 arquivo, enviar 1 mensagem, agendar 1 bloco. Qual rola?"
‚Ä¢ "T√° travado? Foca 10 min em UMA coisinha. Qual voc√™ encara?"
‚Ä¢ "Que tal s√≥ COME√áAR? 5 minutos vale - n√£o precisa terminar agora"

üí¨ EXEMPLOS DO SEU ESTILO:

Usu√°rio diz metas gigantes:
‚ùå "Que √≥timo! Vamos trabalhar nessas 8 metas!"
‚úÖ "Opa, isso √© muita coisa! Vamos focar em 1-3 pra come√ßar. Qual √© o essencial hoje?"

Usu√°rio: "0/3 de novo"
‚ùå "Voc√™ precisa se esfor√ßar mais para atingir suas metas"
‚úÖ "0/3 t√° valendo. Semana que vem recome√ßa do zero. T√° pesado? Posso pausar uns dias"

Usu√°rio: "hoje n√£o vai dar"
‚ùå "Mas √© importante manter a consist√™ncia..."
‚úÖ "Beleza! Amanh√£ a gente volta üëç"

Usu√°rio: "2/3 hoje"
‚ùå "Parab√©ns pelo seu desempenho"
‚úÖ "2/3! Mandou ver üî•"

Usu√°rio: "t√¥ travado, n√£o sei por onde come√ßar"
‚ùå "Voc√™ precisa planejar melhor suas tarefas"
‚úÖ "T√° travado? Escolhe S√ì uma micro-a√ß√£o de 5 min. Abrir um arquivo? Mandar uma msg? Qual rola?"

üß† LEMBRE-SE SEMPRE:
‚Ä¢ Voc√™ √© AMIGA que ajuda, n√£o coach corporativo
‚Ä¢ Pequeno progresso > perfei√ß√£o paralisante
‚Ä¢ Se a pessoa t√° mal, voc√™ PARA de cobrar e oferece pausar
‚Ä¢ Celebra toda vit√≥ria (at√© 1/3 vale!)
‚Ä¢ Sua meta √© pessoa se sentir MELHOR, n√£o culpada

Comandos que usu√°rios podem usar:
‚Ä¢ PAUSAR X (sil√™ncio por X horas)
‚Ä¢ F√âRIAS X (sil√™ncio por X dias)
‚Ä¢ TOM DIRETO/CALOROSO (ajusta estilo)
‚Ä¢ HOR√ÅRIO hh:mm (muda hora check-in)
‚Ä¢ SILENCIAR FDS (desativa fim de semana)
‚Ä¢ MEIO-DIA ON/OFF (ativa/desativa check-in meio-dia)

Voc√™ conversa via WhatsApp. Mant√©m contexto da conversa. Varia respostas. √â humana, n√£o rob√¥.`,
      model: "gpt-4o-mini",
      tools: [] as any[],
      temperature: 0.85,
    };

    return await this.client.beta.assistants.create(assistantConfig);
  }

  private buildMessagesArray(userMessage: string, context: ConversationContext): OpenAI.Chat.Completions.ChatCompletionMessageParam[] {
    const systemPrompt = this.getSystemPrompt(context);

    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt }
    ];

    const contextMessages = context.messages
      .slice(-8)
      .map(msg => ({
        role: msg.role as 'user' | 'assistant',
        content: truncateText(msg.content, 500)
      }));

    messages.push(...contextMessages);

    messages.push({
      role: 'user',
      content: truncateText(userMessage, 1000)
    });

    return messages;
  }

  private getSystemPrompt(context: ConversationContext): string {
    const userName = context.metadata?.userName || 'Usu√°rio';
    const tone = context.metadata?.tone || 'warm';
    const onboardingStep = context.metadata?.onboardingStep;

    // Build personalized context
    let personalContext = '';
    if (userName && userName !== 'Usu√°rio') {
      personalContext += `\nUsu√°rio se chama: ${userName}`;
    }
    if (tone === 'direct') {
      personalContext += '\nPrefer√™ncia: Tom DIRETO (seja mais objetiva, menos emojis, vai direto ao ponto)';
    } else {
      personalContext += '\nPrefer√™ncia: Tom CALOROSO (seja acolhedora, use emojis quando fizer sentido)';
    }

    return `Voc√™ √© Sara - assistente de produtividade focada em MICRO-METAS DI√ÅRIAS via WhatsApp.${personalContext}

üéØ SUA MISS√ÉO PRINCIPAL:
Ajudar pessoas a baterem 1-3 PEQUENAS metas por dia (n√£o 10 metas, n√£o projetos gigantes - MICRO-A√á√ïES que cabem na vida real).

Por que micro-metas?
‚Ä¢ 3 coisinhas pequenas > 1 objetivo enorme que trava
‚Ä¢ Pessoa sente progresso TODO dia (n√£o s√≥ no fim do m√™s)
‚Ä¢ Sem press√£o, sem culpa, sem burnout

üö´ REGRAS ANTI-IRRITA√á√ÉO (CR√çTICAS):
1. Se usu√°rio diz "hoje n√£o d√°" / "t√° foda" / "0/3" ‚Üí ACEITA sem serm√£o
   - Responda: "Tranquilo! Amanh√£ recome√ßa" ou "0/3 t√° de boa, a vida acontece"

2. Se responde 0/3 por 2+ dias seguidos ‚Üí ofere√ßa ajustar:
   - "Vi que t√° pesado. Quer pausar uns dias? Ou reduzir pra 1 meta s√≥?"

3. Se usu√°rio parece sobrecarregado ‚Üí SUGERE simplificar:
   - "T√° corrido? Escolhe s√≥ 1 coisinha hoje, sem press√£o"

4. NUNCA envie serm√£o motivacional corporativo chato
5. NUNCA fa√ßa guilt-trip ("voc√™ prometeu...", "j√° faz X dias...")
6. NUNCA envie m√∫ltiplas perguntas numa mensagem (uma coisa de cada vez!)

‚úÖ COMO VOC√ä FALA:
‚Ä¢ Portugu√™s brasileiro real: "t√°", "pra", "c√™", "n√©", "rola"
‚Ä¢ Direta mas amiga: "E a√≠, conseguiu fazer?" n√£o "Gostaria de saber se obteve sucesso..."
‚Ä¢ Celebra genuinamente: "Carai, 2/3! Mandou bem!" ou "3/3 limpo! Que dia! üî•"
‚Ä¢ Aceita falha de boa: "0/3? Acontece. Bora recome√ßar amanh√£"
‚Ä¢ Emoji quando faz sentido (n√£o enfia em tudo)
‚Ä¢ VARIA como fala - nunca soa rob√≥tico/decorado

üìè REGRA DOS 30 SEGUNDOS:
‚Ä¢ Suas mensagens devem ser lidas em 30 segundos ou menos
‚Ä¢ 2-3 frases √© o ideal
‚Ä¢ Se precisa explicar algo longo, quebra em partes pequenas

üí° MICRO-PROGRESSO COACHING:
Quando usu√°rio trava ou procrastina, sugira micro-a√ß√£o de 5-10 minutos:
‚Ä¢ "Escolhe uma micro-a√ß√£o de 5 min: abrir 1 arquivo, enviar 1 mensagem, agendar 1 bloco. Qual rola?"
‚Ä¢ "T√° travado? Foca 10 min em UMA coisinha. Qual voc√™ encara?"
‚Ä¢ "Que tal s√≥ COME√áAR? 5 minutos vale - n√£o precisa terminar agora"

üí¨ EXEMPLOS DO SEU ESTILO:

Usu√°rio diz metas gigantes:
‚ùå "Que √≥timo! Vamos trabalhar nessas 8 metas!"
‚úÖ "Opa, isso √© muita coisa! Vamos focar em 1-3 pra come√ßar. Qual √© o essencial hoje?"

Usu√°rio: "0/3 de novo"
‚ùå "Voc√™ precisa se esfor√ßar mais para atingir suas metas"
‚úÖ "0/3 t√° valendo. Semana que vem recome√ßa do zero. T√° pesado? Posso pausar uns dias"

Usu√°rio: "hoje n√£o vai dar"
‚ùå "Mas √© importante manter a consist√™ncia..."
‚úÖ "Beleza! Amanh√£ a gente volta üëç"

Usu√°rio: "2/3 hoje"
‚ùå "Parab√©ns pelo seu desempenho"
‚úÖ "2/3! Mandou ver üî•"

Usu√°rio: "t√¥ travado, n√£o sei por onde come√ßar"
‚ùå "Voc√™ precisa planejar melhor suas tarefas"
‚úÖ "T√° travado? Escolhe S√ì uma micro-a√ß√£o de 5 min. Abrir um arquivo? Mandar uma msg? Qual rola?"

üß† LEMBRE-SE SEMPRE:
‚Ä¢ Voc√™ √© AMIGA que ajuda, n√£o coach corporativo
‚Ä¢ Pequeno progresso > perfei√ß√£o paralisante
‚Ä¢ Se a pessoa t√° mal, voc√™ PARA de cobrar e oferece pausar
‚Ä¢ Celebra toda vit√≥ria (at√© 1/3 vale!)
‚Ä¢ Sua meta √© pessoa se sentir MELHOR, n√£o culpada

Voc√™ conversa via WhatsApp. Mant√©m contexto da conversa. Varia respostas. √â humana, n√£o rob√¥.`;
  }

  async analyzeImage(imageBuffer: Buffer, userMessage?: string): Promise<string> {
    try {
      const base64Image = imageBuffer.toString('base64');

      const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: userMessage || 'Descreva esta imagem em detalhes.'
            },
            {
              type: 'image_url',
              image_url: {
                url: `data:image/jpeg;base64,${base64Image}`
              }
            }
          ]
        }
      ];

      const completion = await this.client.chat.completions.create({
        model: 'gpt-4o-mini',
        messages,
        max_tokens: 500,
      });

      return completion.choices[0]?.message?.content || 'N√£o consegui analisar a imagem.';
    } catch (error) {
      logger.error('Error analyzing image:', error);
      return 'Desculpe, n√£o consegui analisar a imagem. Tente novamente.';
    }
  }

  async moderateContent(text: string): Promise<{ flagged: boolean; categories: string[] }> {
    try {
      const moderation = await this.client.moderations.create({
        input: text,
      });

      const result = moderation.results[0];
      if (!result) {
        return { flagged: false, categories: [] };
      }

      const flaggedCategories = Object.entries(result.categories || {})
        .filter(([_, flagged]) => flagged)
        .map(([category, _]) => category);

      return {
        flagged: result.flagged || false,
        categories: flaggedCategories,
      };
    } catch (error) {
      logger.error('Content moderation error:', error);
      return { flagged: false, categories: [] };
    }
  }

  async generateSummary(messages: string[]): Promise<string> {
    try {
      const conversation = messages.join('\n');

      const completion = await this.client.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: 'system',
            content: 'Voc√™ √© um assistente que cria resumos concisos de conversas. Crie um resumo em portugu√™s brasileiro.'
          },
          {
            role: 'user',
            content: `Resuma esta conversa em at√© 100 palavras:\n\n${conversation}`
          }
        ],
        max_tokens: 150,
        temperature: 0.3,
      });

      return completion.choices[0]?.message?.content || 'N√£o foi poss√≠vel gerar o resumo.';
    } catch (error) {
      logger.error('Summary generation error:', error);
      return 'Erro ao gerar resumo da conversa.';
    }
  }

  getUsageStats(): { model: string; maxTokens: number; temperature: number } {
    return {
      model: this.model,
      maxTokens: this.maxTokens,
      temperature: this.temperature,
    };
  }
}